{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXfVRw5p4YOo"
      },
      "source": [
        "# Neural Network on GPU\n",
        "\n",
        "> Author : Badr TAJINI - Machine Learning 2 & Deep learning - ECE 2025-2026\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT49HHnBMPTh"
      },
      "source": [
        "\n",
        "From Kaggle:\n",
        "\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\"\n",
        "\n",
        "[Read more.](https://www.kaggle.com/c/digit-recognizer)\n",
        "\n",
        "\n",
        "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jK-Iyt4NXJoU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq6RJyDIOB-T"
      },
      "source": [
        "## STEP 1: LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aL21SXchOBwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b832717-8891-42d9-8576-329575021c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.04MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.03MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_zuJQxSOKQt"
      },
      "source": [
        "## STEP 2: MAKING DATASET ITERABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bGDbP1pL4XE",
        "outputId": "cc810eb1-0e80-47e5-a208-34321925329e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epochs: 5\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "\n",
        "print(\"Number of epochs: \" + str(num_epochs))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FEft3CQOQIR"
      },
      "source": [
        "## STEP 3: CREATE MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZbEJ-1aAL9d1"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        # Convolution 2\n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Max pool 2\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3owYgg2OWYw"
      },
      "source": [
        "## STEP 4: INSTANTIATE MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dcd2aS_QFzX",
        "outputId": "6296b0ae-63c1-43a3-87e6-abb52650c04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# Number of CUDA devices\n",
        "# The first device is always named \"cuda:0\"\n",
        "# The second one is \"cuda:1\", etc.\n",
        "print(torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dqM6gd4MA2I",
        "outputId": "666a32d1-8739-483f-c37b-e1ebf94ca923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model = CNNModel()\n",
        "\n",
        "####################################################################\n",
        "#  USE GPU FOR MODEL                                               #\n",
        "#  The model must be put on the GPU before declaring the optimizer #\n",
        "####################################################################\n",
        "\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfSU4Nn7GfXS",
        "outputId": "85c5ee2f-84a9-495d-cb7d-47cfe564d1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ArDN205ObQG"
      },
      "source": [
        "## STEP 5: INSTANTIATE LOSS CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YtqarS-WMC5S"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqikNfyhOe7o"
      },
      "source": [
        "## STEP 6: INSTANTIATE OPTIMIZER CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1roaQQwYMFFj"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAaSLaaGrMZ",
        "outputId": "249fb1e4-bd51-47ac-d103-ca670d663e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        "print(model.parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0A9mJ3d6-f8"
      },
      "source": [
        "Function to compute the accuracy on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar07FA9CaiP9"
      },
      "source": [
        "### Question: modify the following code to exploit the GPU instead of the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sv17qSuGO5x6"
      },
      "outputs": [],
      "source": [
        "def test_model(test_loader, model, device):\n",
        "  # Calculate Accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Iterate through test dataset\n",
        "  for images, labels in test_loader:\n",
        "    #######################\n",
        "    #  USE GPU FOR MODEL  #\n",
        "    #######################\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass only to get logits/output\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Get predictions from the maximum value\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Total number of labels\n",
        "    total += labels.size(0)\n",
        "\n",
        "    # Total correct predictions\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "  accuracy = 100 * float(correct) / float(total)\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1) Choisir le bon device (GPU si dispo)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2) Déplacer le modèle sur le device\n",
        "model = model.to(device)\n",
        "\n",
        "def test_model(test_loader, model, device):\n",
        "    model.eval()  # 3) mode eval\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # 4) pas de gradient pendant l'évaluation\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            # 5) données -> GPU/CPU\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "dIqBe_9PQnzl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJWjmbnOhff"
      },
      "source": [
        "## STEP 7: TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZh9Bryn-15o"
      },
      "source": [
        "### Question: modify the following code to exploit the GPU instead of the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ADmEX6UMINe",
        "outputId": "747f7536-ba9b-4898-fdc0-f70d5041ea80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device :  cuda\n",
            "Iteration: 500. Loss: 0.1506587713956833. Accuracy on test set: 93.8\n",
            "Iteration: 1000. Loss: 0.2488403171300888. Accuracy on test set: 94.91\n",
            "Iteration: 1500. Loss: 0.1436598151922226. Accuracy on test set: 95.76\n",
            "Iteration: 2000. Loss: 0.24017883837223053. Accuracy on test set: 96.6\n",
            "Iteration: 2500. Loss: 0.14266470074653625. Accuracy on test set: 96.39\n",
            "Iteration: 3000. Loss: 0.10305536538362503. Accuracy on test set: 97.16\n",
            "CPU times: user 44.5 s, sys: 314 ms, total: 44.8 s\n",
            "Wall time: 46.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Time execution of a Python statement or expression.\n",
        "# wall time is the actual time taken from the start of a computer program to the end\n",
        "print(\"device : \", device)\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy on the test set\n",
        "            accuracy = test_model(test_loader, model, device)\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy on test set: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozPdNeJH-Tfq"
      },
      "source": [
        "### Question: compare the wall time on GPU to the wall time on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "W0xYAafL3bH8",
        "outputId": "58795a0d-534b-4a37-8aeb-6c4b2d2e1698"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFirst result - CPU device\\ndevice :  cpu\\nIteration: 500. Loss: 0.4888801872730255. Accuracy on test set: 87.5\\nIteration: 1000. Loss: 0.37688079476356506. Accuracy on test set: 91.95\\nCPU times: user 34.6 s, sys: 1.12 s, total: 35.7 s\\nWall time: 35.7 s\\n\\nFirst result - GPU device\\ndevice :  cuda:0\\nIteration: 500. Loss: 0.31107470393180847. Accuracy on test set: 88.87\\nIteration: 1000. Loss: 0.2122945636510849. Accuracy on test set: 93.0\\nCPU times: user 12.9 s, sys: 109 ms, total: 13 s\\nWall time: 13 s\\n\\nSecond result - GPU device\\ndevice :  cuda:0\\nIteration: 500. Loss: 0.39977511763572693. Accuracy on test set: 89.4\\nIteration: 1000. Loss: 0.24916988611221313. Accuracy on test set: 92.89\\nIteration: 1500. Loss: 0.23252594470977783. Accuracy on test set: 93.8\\nIteration: 2000. Loss: 0.059734128415584564. Accuracy on test set: 95.59\\nIteration: 2500. Loss: 0.1804923117160797. Accuracy on test set: 96.07\\nIteration: 3000. Loss: 0.07106972485780716. Accuracy on test set: 96.5\\nCPU times: user 32.3 s, sys: 268 ms, total: 32.5 s\\nWall time: 32.6 s\\n\\nSecond result - CPU device \\ndevice :  cpu\\nIteration: 500. Loss: 0.5236935615539551. Accuracy on test set: 88.25\\nIteration: 1000. Loss: 0.21130454540252686. Accuracy on test set: 92.09\\nIteration: 1500. Loss: 0.22272621095180511. Accuracy on test set: 94.18\\nIteration: 2000. Loss: 0.13368134200572968. Accuracy on test set: 95.29\\nIteration: 2500. Loss: 0.17730632424354553. Accuracy on test set: 95.83\\nIteration: 3000. Loss: 0.16622531414031982. Accuracy on test set: 96.33\\nCPU times: user 1min 26s, sys: 1.15 s, total: 1min 27s\\nWall time: 1min 28s\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "'''\n",
        "First result - CPU device\n",
        "device :  cpu\n",
        "Iteration: 500. Loss: 0.4888801872730255. Accuracy on test set: 87.5\n",
        "Iteration: 1000. Loss: 0.37688079476356506. Accuracy on test set: 91.95\n",
        "CPU times: user 34.6 s, sys: 1.12 s, total: 35.7 s\n",
        "Wall time: 35.7 s\n",
        "\n",
        "First result - GPU device\n",
        "device :  cuda:0\n",
        "Iteration: 500. Loss: 0.31107470393180847. Accuracy on test set: 88.87\n",
        "Iteration: 1000. Loss: 0.2122945636510849. Accuracy on test set: 93.0\n",
        "CPU times: user 12.9 s, sys: 109 ms, total: 13 s\n",
        "Wall time: 13 s\n",
        "\n",
        "Second result - GPU device\n",
        "device :  cuda:0\n",
        "Iteration: 500. Loss: 0.39977511763572693. Accuracy on test set: 89.4\n",
        "Iteration: 1000. Loss: 0.24916988611221313. Accuracy on test set: 92.89\n",
        "Iteration: 1500. Loss: 0.23252594470977783. Accuracy on test set: 93.8\n",
        "Iteration: 2000. Loss: 0.059734128415584564. Accuracy on test set: 95.59\n",
        "Iteration: 2500. Loss: 0.1804923117160797. Accuracy on test set: 96.07\n",
        "Iteration: 3000. Loss: 0.07106972485780716. Accuracy on test set: 96.5\n",
        "CPU times: user 32.3 s, sys: 268 ms, total: 32.5 s\n",
        "Wall time: 32.6 s\n",
        "\n",
        "Second result - CPU device\n",
        "device :  cpu\n",
        "Iteration: 500. Loss: 0.5236935615539551. Accuracy on test set: 88.25\n",
        "Iteration: 1000. Loss: 0.21130454540252686. Accuracy on test set: 92.09\n",
        "Iteration: 1500. Loss: 0.22272621095180511. Accuracy on test set: 94.18\n",
        "Iteration: 2000. Loss: 0.13368134200572968. Accuracy on test set: 95.29\n",
        "Iteration: 2500. Loss: 0.17730632424354553. Accuracy on test set: 95.83\n",
        "Iteration: 3000. Loss: 0.16622531414031982. Accuracy on test set: 96.33\n",
        "CPU times: user 1min 26s, sys: 1.15 s, total: 1min 27s\n",
        "Wall time: 1min 28s\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gekTtS1p_v2k"
      },
      "source": [
        "### Question: increase the number of epoch until 5 to see if we can expect a better average accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-6riSeSc5Srr",
        "outputId": "e1184186-3b5a-4f90-bb05-58588e544c0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nn_iters = 1200 \\nCPU => Accuracy on test set: 91.95\\nGPU => Accuracy on test set: 93.0\\n\\nn_iters = 3000\\nCPU => Accuracy on test set: 96.33\\nGPU => Accuracy on test set: 96.5\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "'''\n",
        "n_iters = 1200\n",
        "CPU => Accuracy on test set: 91.95\n",
        "GPU => Accuracy on test set: 93.0\n",
        "\n",
        "n_iters = 3000\n",
        "CPU => Accuracy on test set: 96.33\n",
        "GPU => Accuracy on test set: 96.5\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the number of epochs is already 5."
      ],
      "metadata": {
        "id": "IBlyQ-izRdEU"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}